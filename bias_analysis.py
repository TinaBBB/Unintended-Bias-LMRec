# -*- coding: utf-8 -*-
"""
Automatically generated by Colaboratory.
Original file is located at
    https://colab.research.google.com/drive/1ttOPp2eEhH3_MilI1ghIFJJuFjX9h591

# This notebook contains the necessary code for the experimental results visualisation
Run the following to get the right package access
$apt-get install xvfb libgtk2.0-0 libgconf-2-4
$chmod +x /usr/local/bin/orca
"""

import argparse
import gc
import os
import pickle
import matplotlib.pyplot as plt
import nltk
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import plotly.io._orca
import retrying
import seaborn as sns
from nltk.corpus import stopwords
from scipy import stats
from tqdm import tqdm
import warnings
from wordcloud import WordCloud

from config.configs import city_list, replacements
from utils.bias_analysis_utils import create_occupationPlotDf, get_counts, get_counts_so, get_counts_so_wFolds, get_counts_wFold, get_deviation_score, \
    get_fraction_df, \
    get_price_ratio_df, \
    get_price_ratio_df_wFold, \
    getOccupation_df, mean_confidence_interval, \
    plot_barChart, plot_scatter
from utils.utils import concat_city_df, multireplace

warnings.filterwarnings("ignore")

nltk.download('stopwords')
stopwords = stopwords.words('english')
sns.set_style("darkgrid")
# sns.set_theme(style="ticks", color_codes=True)


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_dir', type=str, default='data/Yelp_cities')
    parser.add_argument('--statistics_df_dir', type=str, default='data/bias_analysis/yelp/statistics.csv', help='the csv file that stores the '
                                                                                                                   'datset statistics, alternative '
                                                                                                                   'path for gender: '
                                                                                                                   'gender_statistics.csv')
    parser.add_argument('--city_name', type=str, default='Austin')
    parser.add_argument('--experiment', type=str, default='5f', help='experiment title, including 5f, 4f, 5n')
    parser.add_argument('--subExp', type=str, default='freezeBoth', help='sub-experiment for 5n, deciding which layers to freeze')
    parser.add_argument('--save_figure', action='store_true', help='whether to save the figures')
    parser.add_argument('--test_neutralization', action='store_true', help='whether to perform test-side neutralization towards the results')
    parser.add_argument('--rank_threshold_all', type=int, default=20, help='number of top recommendations to analyse')
    parser.add_argument('--sample_number', type=int, default=0, help='number of samples for subsampling in the price-ratio analysis')
    parser.add_argument('--fold_number_correlations', type=int, default=0, help='number of folds to use to calculate the dataset-recommendation'
                                                                                'correlation')
    parser.add_argument('--prob_choice_2d_plot', type=str, default='difference', help="probability choice for creating the 2d categories plot, "
                                                                                      "alternatively can use 'ratio'")
    p = parser.parse_args()

    """
    Settings
    """

    # Rename city list for experiment 5n
    new_city_list = list()
    if p.experiment == '5n':
        for city in city_list:
            new_city_list.append('{}_{}'.format(city, p.subExp))
        city_list = new_city_list.copy()
    del new_city_list
    gc.collect()
    print("City list:", city_list)

    if p.experiment == '5n':
        bias_placeholder_dir = 'data/bias_analysis/yelp/output_dataframes/{}_output_dataframes_{}/{}/'
    else:
        bias_placeholder_dir = 'data/bias_analysis/yelp/output_dataframes/{}_output_dataframes_{}/'
    neutralizedBias_placeholder_dir = 'data/bias_analysis/yelp/output_dataframes/{}_output_dataframes_Neutralized/'
    saveFigure_dir = 'bias_analysis/yelp/figures_{}/'.format(p.experiment)
    if not os.path.exists(saveFigure_dir):
        os.makedirs(saveFigure_dir)

    """ 
    1.Price ratio for race
    """
    print('-' * 20 + 'Generating bar charts for price ratio' + '-' * 20)
    df_list = []
    for cityName in city_list:
        origin_cityName = cityName
        if '_' in cityName:
            cityName, subExp = cityName.split('_')

        # get reading directory
        if p.experiment == '5n':
            temp_bias_dir = bias_placeholder_dir.format(cityName, p.experiment, subExp)
        else:
            temp_bias_dir = bias_placeholder_dir.format(cityName, p.experiment)

        temp_url = temp_bias_dir + 'yelp_qa_names.csv'
        temp_df_names = pd.read_csv(temp_url, index_col=0)
        if cityName == 'Toronto':
            temp_df_names['price_lvl'] = temp_df_names['price'].str.len()
        else:
            temp_df_names['price_lvl'] = temp_df_names['price']

        temp_df_price_ratio_plot = get_price_ratio_df(temp_df_names)
        temp_df_price_ratio_plot['city'] = origin_cityName
        df_list.append(temp_df_price_ratio_plot)

    # concatenate all dataframes
    df_avg_city_plot = pd.concat(df_list, ignore_index=True)

    # you decide the sample number here
    if p.sample_number == 0:
        sample_number = len(temp_df_names[temp_df_names['label'] == 'white'].example_label.unique())
    # calculate error bar for the averaged data
    summarize_df = df_avg_city_plot[df_avg_city_plot['bias'] == 'race']
    summarize_df = summarize_df.groupby(['label', 'price_lvl'])['ratio'].mean().reset_index(name='mean_ratio')

    # calculate the sample standard deviation
    for idx, row in summarize_df.iterrows():
        cur_label = row['label']
        cur_priceLvl = row['price_lvl']
        mean_ratio = row['mean_ratio']

        # sample values
        city_x = df_avg_city_plot[(df_avg_city_plot['label'] == cur_label) &
                                  (df_avg_city_plot['price_lvl'] == cur_priceLvl)]['ratio']
        std = (sum([(x - mean_ratio) ** 2 for x in city_x]) / sample_number) ** 0.5
        summarize_df.loc[(summarize_df['price_lvl'] == cur_priceLvl) & (summarize_df['label'] == cur_label), ['lb', 'ub']] = std

    fig, axes = plt.subplots(2, 4, figsize=(18, 9.6))
    axes = axes.flatten()

    # loop through each city to create the plot
    for c_idx, c in enumerate(df_avg_city_plot.city.unique()):
        g = sns.barplot(x="price_lvl", y="ratio", hue='label',
                        data=df_avg_city_plot[(df_avg_city_plot['bias'] == 'race') & (df_avg_city_plot['city'] == c)], ax=axes[c_idx],
                        saturation=1)
        # Neutralization line
        g.axhline(0.5, ls='--', c='gray', label='neutral reference')

        f = sns.pointplot(x="price_lvl", y="ratio", hue='label',
                          data=df_avg_city_plot[(df_avg_city_plot['bias'] == 'race') & (df_avg_city_plot['city'] == c)], ax=axes[c_idx],
                          legend=False, saturation=1)

        # calculate slope and correlation coefficient
        cur_city = df_avg_city_plot[(df_avg_city_plot['city'] == c) & (df_avg_city_plot['bias'] == 'race')]
        white_ratio = cur_city[cur_city['label'] == 'white'].ratio
        price_lvl = cur_city.price_lvl.unique()
        res = stats.linregress(price_lvl, white_ratio)

        axes[c_idx].set_title(c + '\n', fontsize=13)
        g.set(xlabel='', ylabel='', ylim=(0.1, None))
        g.legend_.set_title(None)
        g.legend_.set_visible(False)

    # calculate pearson correlation for all
    white_ratio = summarize_df[summarize_df['label'] == 'white'].mean_ratio
    price_lvl = summarize_df.price_lvl.unique()
    res = stats.linregress(price_lvl, white_ratio)

    # plot average over cities
    errLo = summarize_df.pivot(index="price_lvl", columns="label", values="lb")
    errHi = summarize_df.pivot(index="price_lvl", columns="label", values="ub")
    err = []
    for col in errLo:
        err.append([errLo[col].values, errHi[col].values])
    err = np.abs(err)
    plot_df = summarize_df.pivot(index="price_lvl", columns="label", values="mean_ratio")
    ax = plot_df.plot(kind='bar', yerr=err, ax=axes[c_idx + 1], width=0.9, xlabel='', ylabel='')
    ax.set_title("All", fontdict={'fontsize': 13})
    ax.set_ylim(0.1)
    ax.axhline(0.5, color="gray", linestyle="--", label='neutral reference')

    plt.legend(loc='upper center', bbox_to_anchor=[0.5, 0.99], ncol=4,
               bbox_transform=plt.gcf().transFigure, fontsize=13)
    fig.text(0.06, 0.35, '% at price level recommended', rotation='vertical', fontsize=16)
    fig.text(0.08, 0.5, 'to race', rotation='vertical', fontsize=16)
    fig.text(0.46, 0.07, 'price level ($)', fontsize=16)

    if p.save_figure:
        fig.savefig(saveFigure_dir + 'price_level_ratio_All_Cities.pdf', bbox_inches='tight')

    """ 1.1 Calculate Deviation Scores and save to model performance folder """
    print('-' * 20 + 'Calculating Deviation Scores, saving to model performance folder' + '-' * 20)
    print(p.experiment, p.subExp)
    if p.experiment == '5n':
        temp_result_dir = 'performance_analysis/{}/{}/'.format(p.experiment, subExp)
    else:
        temp_result_dir = 'performance_analysis/{}/'.format(p.experiment)
    print('Saving deviation score table into directory:', temp_result_dir)

    deviation_score_list = ['Mean AD', 'Median AD', 'Max AD', 'Std']
    for bias_type in ['gender', 'race']:
        deviation_df = pd.DataFrame(columns=['City'] + deviation_score_list)

        for city in df_avg_city_plot['city'].unique().tolist():
            row = {'City': city}
            deviation = np.array(
                df_avg_city_plot[(df_avg_city_plot['city'] == city) & (df_avg_city_plot['bias'] == bias_type)]['ratio'].to_list()) - 0.5
            get_deviation_score(deviation, deviation_score_list, row)
            # deviation_df = deviation_df.append(row, ignore_index=True)
            deviation_df = pd.concat([deviation_df, pd.DataFrame.from_records([row])])

        row = {'City': 'Overall'}
        deviation = np.array(df_avg_city_plot[df_avg_city_plot['bias'] == bias_type]['ratio'].to_list()) - 0.5
        get_deviation_score(deviation, deviation_score_list, row)
        # deviation_df = deviation_df.append(row, ignore_index=True)
        deviation_df = pd.concat([deviation_df, pd.DataFrame.from_records([row])])
        deviation_df.to_csv(temp_result_dir + 'performance_deviationScore_{}.csv'.format(bias_type), index=False)

    print('Deviation scores saved')

    """
    1.2 Calculate correlations
    """
    print('1.2 Calculating correlations')
    correlations_save_dir = 'bias_analysis/yelp/figures_{}/correlation_{}.pdf'

    if p.fold_number_correlations != 0:
        df_list = []
        for cityName in city_list:
            origin_cityName = cityName
            if '_' in cityName:
                cityName, subExp = cityName.split('_')

            if p.experiment == '5n':
                temp_bias_dir = bias_placeholder_dir.format(cityName, p.experiment, subExp)
            else:
                temp_bias_dir = bias_placeholder_dir.format(cityName, p.experiment)

            temp_url = temp_bias_dir + 'yelp_qa_names.csv'
            temp_df_names = pd.read_csv(temp_url, index_col=0)
            if cityName == 'Toronto':
                temp_df_names['price_lvl'] = temp_df_names['price'].str.len()
            else:
                temp_df_names['price_lvl'] = temp_df_names['price']

            temp_df_price_ratio_plot = get_price_ratio_df_wFold(temp_df_names, fold=p.fold_number_correlations)
            temp_df_price_ratio_plot['city'] = origin_cityName
            df_list.append(temp_df_price_ratio_plot)

        # concatenate all dataframes
        price_ratio_df = pd.concat(df_list, ignore_index=True)
        recommendation_df = price_ratio_df.copy()  # if apply fold number
    else:
        recommendation_df = df_avg_city_plot.copy()  # if use original data

    recommendation_df = recommendation_df.rename(columns={"ratio": "ratio_recommendation"})

    """Get statistics dataframe"""
    statistics_df = pd.read_csv(p.statistics_df_dir)
    statistics_df = statistics_df.rename(columns={"City": "city",
                                                  "Price_level": "price_lvl",
                                                  "Category": "bias",
                                                  "Percent": "percent_stats",
                                                  "Type": "label", })
    statistics_df['percent_stats'] = statistics_df['percent_stats'] / 100
    statistics_df['price_lvl'] = statistics_df['price_lvl'].str.len()
    statistics_df['label'] = statistics_df['label'].str.lower()
    statistics_df['bias'] = statistics_df['bias'].str.lower()

    df_join = pd.merge(recommendation_df, statistics_df, how='left', on=['city',
                                                                         'price_lvl',
                                                                         'bias',
                                                                         'label'])

    race_percentStats = statistics_df[statistics_df['bias'] == 'race']['percent_stats'].to_list()
    gender_percentStats = statistics_df[statistics_df['bias'] == 'gender']['percent_stats'].to_list()

    """1.2.1 Gender"""

    gender_polarity = ['male', 'female']
    gender_ratio_df = df_join[df_join['bias'] == 'gender']

    """Overall"""
    # get fraction or difference dataframe dataframe
    for calculation_method in ['fraction', 'difference']:
        gender_frac_df = get_fraction_df(bias_ratio_df=gender_ratio_df,
                                         bias_polarity=gender_polarity,
                                         calculation_method=calculation_method)
        plot_scatter(gender_frac_df[['percent_stats', 'ratio_recommendation']],
                     bias_polarity=gender_polarity,
                     calculation_method=calculation_method,
                     title='Gender',
                     withTrend=True,
                     save_dir=correlations_save_dir.format(p.experiment, 'gender_overall_'+calculation_method))

    """Overall - no $$$$"""
    # get fraction or difference dataframe dataframe
    disgard_price = 4
    for calculation_method in ['fraction', 'difference']:
        gender_frac_df = get_fraction_df(bias_ratio_df=gender_ratio_df,
                                         bias_polarity=gender_polarity,
                                         calculation_method=calculation_method)
        plot_scatter(gender_frac_df[gender_frac_df['price_lvl'] != disgard_price][['percent_stats', 'ratio_recommendation']],
                     bias_polarity=gender_polarity,
                     calculation_method=calculation_method,
                     title='Gender - no {}'.format('\$' * disgard_price),
                     withTrend=True,
                     save_dir=correlations_save_dir.format(p.experiment, 'gender_overall_no$$$$_'+calculation_method))

    """1.2.2 Race"""

    race_polarity = ['white', 'black']
    race_ratio_df = df_join[(df_join['bias'] == 'race')]
    race_frac_df = get_fraction_df(bias_ratio_df=race_ratio_df, bias_polarity=race_polarity, calculation_method='difference')

    """Overall"""
    # get fraction or difference dataframe dataframe
    for calculation_method in ['fraction', 'difference']:
        race_frac_df = get_fraction_df(bias_ratio_df=race_ratio_df,
                                       bias_polarity=race_polarity,
                                       calculation_method=calculation_method)
        plot_scatter(race_frac_df[['percent_stats', 'ratio_recommendation']],
                     bias_polarity=race_polarity,
                     calculation_method=calculation_method,
                     title='Race',
                     withTrend=True,
                     save_dir=correlations_save_dir.format(p.experiment, 'race_overall_'+calculation_method))

    """Without $$$$"""
    # get fraction or difference dataframe dataframe
    disgard_price = 4
    for calculation_method in ['fraction', 'difference']:
        race_frac_df = get_fraction_df(bias_ratio_df=race_ratio_df,
                                       bias_polarity=race_polarity,
                                       calculation_method=calculation_method)
        plot_scatter(race_frac_df[race_frac_df['price_lvl'] != disgard_price][['percent_stats', 'ratio_recommendation']],
                     bias_polarity=race_polarity,
                     calculation_method=calculation_method,
                     title='Race - no {}'.format('\$' * disgard_price),
                     withTrend=True,
                     save_dir=correlations_save_dir.format(p.experiment, 'race_overall_no$$$$_'+calculation_method))

    """
    2.Joint scatter plot for price ratio for race
    """
    print('-' * 20 + 'Generating scatter plot for price ratio for racial bias' + '-' * 20)
    df_list_joint = []
    for cityName in city_list:
        temp_bias_dir = bias_placeholder_dir.format(cityName, p.experiment)
        temp_url = temp_bias_dir + 'yelp_qa_names.csv'
        temp_df_names = pd.read_csv(temp_url, index_col=0)
        if cityName == 'Toronto':
            temp_df_names['price_lvl'] = temp_df_names['price'].str.len()
        else:
            temp_df_names['price_lvl'] = temp_df_names['price']

        temp_df_names['city'] = cityName
        df_list_joint.append(temp_df_names)

    # concatenate all dataframes
    df_avg_city_joint_plot = pd.concat(df_list_joint, ignore_index=True)

    df_price_ratio_joint = pd.DataFrame()
    for name in df_avg_city_joint_plot.example_label.unique():
        # retrieve entries for current name
        current_df = df_avg_city_joint_plot[df_avg_city_joint_plot['example_label'] == name][['city', 'label', 'price_lvl', 'avg_stars', 'rank']]
        # supposed to have two types of labels here one for race, the other for gender
        current_biases = current_df['label'].unique().tolist()
        # continue if not joint
        if len(current_biases) != 2:
            continue
        current_df['joint_bias'] = ', '.join(current_biases)
        df_price_ratio_joint = df_price_ratio_joint.append(current_df, ignore_index=True)

    # calculate the ratio
    df_price_ratio_joint_groupby = df_price_ratio_joint.groupby(by=['city', 'label', 'joint_bias', 'price_lvl']).size().reset_index(name='counts')
    df_price_ratio_joint_plot = pd.DataFrame()
    for idx, row in df_price_ratio_joint_groupby.iterrows():
        price = row['price_lvl']
        bias = row['joint_bias']
        city = row['city']
        deno = sum(df_price_ratio_joint_groupby[
                       (df_price_ratio_joint_groupby['price_lvl'] == price) & (df_price_ratio_joint_groupby['city'] == city)].counts) / 2
        ratio = row['counts'] / deno
        row['ratio'] = ratio
        df_price_ratio_joint_plot = df_price_ratio_joint_plot.append(row)

    # for all plots
    df_price_ratio_joint_plot_Avgcities = df_price_ratio_joint_plot.copy()
    df_price_ratio_joint_plot_Avgcities['city'] = all
    df_price_ratio_joint_plot['ratio'] = df_price_ratio_joint_plot['ratio'] * 100
    sns.set_style("white")

    f = sns.catplot(x="price_lvl", y="ratio", hue='joint_bias', kind='point', col='label', units='city',
                    data=df_price_ratio_joint_plot[df_price_ratio_joint_plot['label'].isin(['female', 'male'])], ci=90,
                    legend=False, dodge=0.1)
    plt.axhline(25, ls='--', c='gray')

    ''' add neutralized line'''
    ax1, ax2 = f.axes[0]
    ax1.axhline(25, ls='--', c='gray')
    ax2.axhline(25, ls='--', c='gray', label='neutral reference')

    f.set_xlabels('')
    f.set_ylabels('')
    f.set_titles("")
    plt.legend(loc='upper center', bbox_to_anchor=[0.52, 1.05], ncol=5, fontsize=13,
               bbox_transform=plt.gcf().transFigure)
    plt.text(-5.5, 16, '% at price level recommended',
             rotation='vertical', fontsize=16)
    plt.text(-5.3, 20, 'to race & gender', rotation='vertical', fontsize=16)
    plt.text(-1.2, 12, 'price level', fontsize=16)

    if p.save_figure:
        plt.savefig(saveFigure_dir + 'price_ratio_scatters_race.pdf', bbox_inches='tight')

    """3.The 2D plot for association score"""
    print('-' * 20 + 'Generating 2D plot for association scores' + '-' * 20)
    fold_number = 20
    split_number = 4

    # load all cities into one dataframe
    df_city_all_plot = concat_city_df(city_list, bias_placeholder_dir, p, file_name='yelp_qa_names.csv')

    # indicates how many front recommended items we want to check
    rank_bar = 20
    np.random.seed(68)

    df_cat_all = None
    df_sum_all = None

    for split_num in range(split_number):
        df_temp = df_city_all_plot[df_city_all_plot['rank'] <= rank_bar]
        df_temp['fold'] = np.random.randint(0, fold_number, df_temp.shape[0])

        if df_cat_all is None:
            df_cat_all = df_temp.copy()
        else:
            df_cat_all = df_cat_all.append(df_temp, ignore_index=True)

        df_temp_sum = df_temp.groupby(by=['label', 'fold']).size().reset_index(name='counts')

        if df_sum_all is None:
            df_sum_all = df_temp_sum.copy()
        else:
            df_sum_all = df_sum_all.append(df_temp_sum, ignore_index=True)
            # df_sum_all = pd.concat(df_sum_all,df_temp_sum)

    # nested dictionary
    # {cat1: {'fold0': {'female':0, 'male':0, 'white':0,'black':0}, 'fold1':{}...}, cat2:{}...}
    jointCount_dict = dict()
    for index, row in tqdm(df_cat_all[['categories', 'label', 'fold']].iterrows()):
        cats_string = row['categories']
        text = multireplace(cats_string, replacements)
        cats_list = text.lower().split(',')
        for cat in cats_list:
            cat = cat.strip()
            label = row['label']
            fold_n = row['fold']

            innerDict = jointCount_dict.get(cat, dict())
            mostInnerDict = innerDict.get(fold_n, dict())
            mostInnerDict[label] = mostInnerDict.get(label, 0) + 1
            innerDict[fold_n] = mostInnerDict
            jointCount_dict[cat] = innerDict

    plot_df_all = pd.DataFrame()

    # use the difference
    point_list = []

    with open('data/bias_analysis/yelp/Category_set_2D.txt', 'rb') as f:
        Category_set_2D = pickle.load(f)
    for name in Category_set_2D:  # USE THIS FOR CLEANER VERSION
        xVal_list = list()
        yVal_list = list()

        # loop through each fold
        for fold_num in range(fold_number):
            # get joint count
            # white
            x_white, x_white_count, x_white_baseCount = get_counts_wFold(df_sum_all, jointCount_dict,  name, label='white', fold_num=fold_num)
            # black
            x_black, x_black_count, x_black_baseCount = get_counts_wFold(df_sum_all, jointCount_dict, name, label='black', fold_num=fold_num)
            # male
            y_male, y_male_count, y_male_baseCount = get_counts_wFold(df_sum_all, jointCount_dict, name, label='male', fold_num=fold_num)
            # female
            y_female, y_female_count, y_female_baseCount = get_counts_wFold(df_sum_all, jointCount_dict, name, label='female', fold_num=fold_num)

            if p.prob_choice_2d_plot == 'ratio':
                x_val_temp = np.log(1e-4 + x_white / (x_black + 1e-4))
                y_val_temp = np.log(1e-4 + y_female / (y_male + 1e-4))
            elif p.prob_choice_2d_plot == 'difference':
                x_val_temp = (x_white - x_black) / (1e-4 + (x_white_count + x_black_count) / (1e-4 + x_white_baseCount + x_black_baseCount))
                y_val_temp = (y_female - y_male) / (1e-4 + (y_female_count + y_male_count) / (1e-4 + y_male_baseCount + y_female_baseCount))
            else:
                raise NotImplementedError('need to choose a valid probability type')
            xVal_list.append(x_val_temp)
            yVal_list.append(y_val_temp)

        # calculate the aggregated value and error bars
        x_val, x_err = mean_confidence_interval(xVal_list, confidence=0.90, n=len(xVal_list) * split_number)
        y_val, y_err = mean_confidence_interval(yVal_list, confidence=0.90, n=len(xVal_list) * split_number)

        point_list.append([name, x_val, y_val, x_err, y_err])
        plot_df_all = plot_df_all.append({'category': name,
                                          'score': x_val,
                                          'err': x_err,
                                          'kind': 'race',
                                          'bottom': 'black',
                                          'top': 'white'}, ignore_index=True)

        plot_df_all = plot_df_all.append({'category': name,
                                          'score': y_val,
                                          'err': y_err,
                                          'kind': 'gender',
                                          'bottom': 'male',
                                          'top': 'female'}, ignore_index=True)
        # texts.append(plt.text(x_val, y_val, name))

    # For saving the image.
    unwrapped = plotly.io._orca.request_image_with_retrying.__wrapped__
    wrapped = retrying.retry(wait_random_min=1000)(unwrapped)
    plotly.io._orca.request_image_with_retrying = wrapped

    """showing for neutralized data"""
    fig = go.Figure()
    short_dict = {'wine bars': 'wine'}
    location_dict = {'juice bars & smoothies': 'top center', 'mediterranean': 'bottom right', 'desserts': 'top center', 'cafes': 'top center',
                     'fish & chips': 'bottom right', 'pizza': 'top right', 'canadian (new)': 'bottom right', 'gastropubs': 'bottom right',
                     'argentine': 'bottom right', 'brewpubs': 'bottom right', 'smokehouse': 'bottom right', 'whiskey bars': 'bottom right',
                     'italian': 'bottom right', 'tapas bars': 'bottom right',
                     'burgers': 'bottom right', 'mauritius': 'bottom left', 'chicken wings': 'bottom left',
                     'jazz & blues': 'top center', 'breakfast & brunch': 'top right', 'filipino': 'bottom left',
                     'wine bars': 'bottom right', 'austrian': 'bottom left',
                     'salad': 'bottom right', 'irish pub': 'bottom left', 'arabian': 'bottom right', 'patisserie': 'bottom right',
                     'cideries': 'bottom left', 'food court': 'top right', 'puerto rican': 'bottom right',
                     'coffee roasteries': 'top left', 'waffles': 'bottom left',
                     'coffee & tea': 'bottom right', 'cocktail bars': 'top left', 'shaved ice': 'bottom right',
                     'nepalese': 'bottom right', 'wine': 'top left', 'south african': 'top left', 'champagne bars': 'bottom left'}

    for item in point_list:
        n, v1, v2, err1, err2 = item
        if err1 >= 0.1 or err2 >= 0.1: continue
        if n in ['catalan', 'bars', 'persian', 'fischbroetchen', 'british', 'dive bars',
                 'wineries', 'pretzels', 'mauritius', 'sandwiches', 'beer bar', 'cider',
                 'meaderies', 'sports clubs', 'puerto rican']:
            continue
        if n in short_dict.keys():
            n = short_dict[n]

        fig.add_trace(go.Scatter(
            x=[v1],
            y=[v2],
            mode="markers+text",
            name=n,
            text=[n],
            marker=dict(size=8),
            textposition="bottom center" if n not in location_dict else location_dict[n],
            showlegend=False,
            error_y=dict(
                type='data',
                array=[err2],
                visible=True),
            error_x=dict(
                type='data',
                array=[err1],
                visible=True)

        ))
    # add neutralization point
    opacity_list = [1, 0.8, 0.6, 0.4, 0.2, 0.1]
    for idx, op in enumerate(opacity_list):
        fig.add_trace(go.Scatter(
            x=[0],
            y=[0],
            opacity=op,
            mode="markers",
            name='neutralization',
            text=[''],
            marker=dict(size=idx * 20, color='gray'),
            textposition="bottom center",
            showlegend=False,
        ))

    fig.update_layout(
        autosize=True,
        height=600,
        width=1800,
        margin=go.layout.Margin(
            l=0,  # left margin
            r=0,  # right margin
            b=0,  # bottom margin
            t=0,  # top margin
        ),
        xaxis=dict(
            title=dict(
                text=r"$ \Large\mathrm{black} \longleftarrow \longrightarrow \mathrm{white}$",
                font=dict(size=40))
            , range=[-0.85, 0.85]
        ),
        yaxis=dict(
            title=dict(
                text=r"$ \Large\mathrm{male} \longleftarrow \longrightarrow \mathrm{female}$",
                font=dict(size=40))
            , range=[-0.75, 0.75]
        ),
        font=dict(
            family="Times New Roman",
            size=24
        ))

    if p.save_figure:
        fig.write_image("{}all_categories_2D.pdf".format(saveFigure_dir), scale=1, width=1850, height=600)

    """4.The 2D plot for nightlife"""
    print('-' * 20 + 'Generating 2D plot for nightlife' + '-' * 20)
    fold_number = 10  # number of folds per validation
    split_number = 4  # number of cross validations

    # load all cities into one dataframe
    df_sex_orien = concat_city_df(city_list, bias_placeholder_dir, p, 'yelp_qa_relationships.csv')
    df_sex_orien['status'] = np.where(df_sex_orien['label'] == df_sex_orien['secondary_label'], 'homosexual', 'heterosexual')
    df_sex_orien['distribution'] = ''

    # Adding in the fold numbers
    np.random.seed(68)
    df_sex_orien_all = None
    df_sum_sex_orien_all = None

    for split_num in range(split_number):
        df_temp = df_sex_orien[df_sex_orien['rank'] <= p.rank_threshold_all]
        df_temp['fold'] = np.random.randint(0, fold_number, df_temp.shape[0])

        if df_sex_orien_all is None:
            df_sex_orien_all = df_temp.copy()
        else:
            df_sex_orien_all = df_sex_orien_all.append(df_temp, ignore_index=True)

        df_temp_sum = df_temp.groupby(by=['label', 'fold']).size().reset_index(name='counts')

        if df_sum_sex_orien_all is None:
            df_sum_sex_orien_all = df_temp_sum.copy()
        else:
            df_sum_sex_orien_all = df_sum_sex_orien_all.append(df_temp_sum, ignore_index=True)

    lst = df_sex_orien_all.categories.values.tolist()
    lst = list(set(lst))

    # create dictionary for counting each bias label under different fold and category
    # {cat1:{fold0:{female_first: #, female_second:#, male_first:#, male_second:#}}}
    jointCount_dict = dict()
    for index, row in tqdm(df_sex_orien_all[['categories', 'label', 'secondary_label', 'fold']].iterrows()):
        cats_string = row['categories']
        text = multireplace(cats_string, replacements)
        cats_list = text.lower().split(',')
        for cat in cats_list:
            cat = cat.strip()
            label1 = row['label'] + '_first'
            label2 = row['secondary_label'] + '_second'
            fold_n = row['fold']

            innerDict = jointCount_dict.get(cat, dict())
            mostInnerDict = innerDict.get(fold_n, dict())
            mostInnerDict[label1] = mostInnerDict.get(label1, 0) + 1
            mostInnerDict[label2] = mostInnerDict.get(label2, 0) + 1
            innerDict[fold_n] = mostInnerDict
            jointCount_dict[cat] = innerDict

    nightlife_list = {
        'arcades', 'bars', 'bar crawl', 'beer', 'beer bar', 'brewpubs', 'cabaret',
        'dance clubs', 'champagne bars', 'cocktail bars', 'dance clubs', 'dive bars', 'gastropubs',
        'gay bars', 'hookah bars', 'irish pub', 'izakaya', 'jazz & blues', 'karaoke', 'lounges',
        'pool halls', 'pool & billiards', 'music venues', 'nightlife', 'party supplies', 'piano bars', 'pubs',
        'recreation centers', 'sports bars', 'sports clubs', 'tabletop games', 'tapas bars',
        'tiki bars', 'whiskey bars', 'wine & spirits', 'wine bars'}

    plot_df_all = pd.DataFrame()
    point_list = []
    # loop through each category
    for name in nightlife_list:
        xVal_list = list()
        yVal_list = list()
        jointX_count = 0
        jointY_count = 0

        for fold_num in range(fold_number):
            # get joint count
            # female1
            x_female1, x_female_count1, x_female_baseCount1 = get_counts_so_wFolds(df_sum_sex_orien_all, jointCount_dict,  name, label='female_first',
                                                                                   fold_num=fold_num)
            # male1
            x_male1, x_male_count1, x_male_baseCount1 = get_counts_so_wFolds(df_sum_sex_orien_all, jointCount_dict, name, label='male_first', fold_num=fold_num)
            # female2
            y_female2, y_female_count2, y_female_baseCount2 = get_counts_so_wFolds(df_sum_sex_orien_all, jointCount_dict, name, label='female_second',
                                                                                   fold_num=fold_num)
            # male2
            y_male2, y_male_count2, y_male_baseCount2 = get_counts_so_wFolds(df_sum_sex_orien_all, jointCount_dict, name, label='male_second', fold_num=fold_num)

            jointX_count += x_female_count1 + x_male_count1
            jointY_count += y_female_count2 + y_male_count2

            if p.prob_choice_2d_plot == 'ratio':
                x_val_temp = np.log(1e-4 + x_female1 / (x_male1 + 1e-4))
                y_val_temp = np.log(1e-4 + y_female2 / (y_male2 + 1e-4))
            elif p.prob_choice_2d_plot == 'difference':
                x_val_temp = (x_female1 - x_male1) / (1e-4 + (x_female_count1 + x_male_count1) / (1e-4 + x_female_baseCount1 + x_male_baseCount1))
                y_val_temp = (y_female2 - y_male2) / (1e-4 + (y_female_count2 + y_male_count2) / (1e-4 + y_female_baseCount2 + y_male_baseCount2))
            else:
                raise NotImplementedError('need to choose a valid probability type')

            if abs(x_val_temp) >= 1e-4:
                xVal_list.append(x_val_temp)
            if abs(y_val_temp) >= 1e-4:
                yVal_list.append(y_val_temp)

        # calculate the aggregated value and error bars
        x_val, x_err = mean_confidence_interval(xVal_list, confidence=0.90, n=jointX_count * split_number)
        y_val, y_err = mean_confidence_interval(yVal_list, confidence=0.90, n=jointY_count * split_number)

        point_list.append([name, x_val, y_val, x_err, y_err])
        plot_df_all = plot_df_all.append({'category': name,
                                          'score': x_val,
                                          'err': x_err,
                                          'kind': 'first_gender',
                                          'bottom': 'male',
                                          'top': 'female'}, ignore_index=True)

        plot_df_all = plot_df_all.append({'category': name,
                                          'score': y_val,
                                          'err': y_err,
                                          'kind': 'second_gender',
                                          'bottom': 'male',
                                          'top': 'female'}, ignore_index=True)

    plt.rcParams['mathtext.default'] = 'regular'

    # use plotly
    fig = go.Figure()
    x_min = -0.75
    x_max = 0.75
    y_min = -0.4
    y_max = 0.4

    for item in point_list:
        n, v1, v2, err1, err2 = item

        if err1 >= 0.1 or err2 >= 0.1:
            continue

        avoid_list = ['bars', 'beer bar', 'nightlife', 'music venues', 'gastropubs']

        if n in avoid_list: continue
        location_dict = {'social clubs': 'top right', 'recreation centers': 'bottom right',
                         'party supplies': 'top right', 'tiki bars': 'top right',
                         'karaoke': 'bottom left', 'sports bars': 'bottom left',
                         'night life': 'bottom left', 'music venues': 'top right',
                         'wine & spirits': 'top right', 'nightlife': 'bottom left',
                         'beer bar': 'bottom left', 'wine bars': 'bottom center', 'jazz & blues': 'top left',
                         'tapas bars': 'top right', 'brewpubs': 'bottom left', 'lounges': 'bottom left',
                         'bar crawl': 'top right', 'beer': 'bottom right', 'izakaya': 'top right',
                         'casinos': 'bottom right', 'whiskey bars': 'top left', 'piano bars': 'bottom left',
                         'tabletop games': 'bottom left', 'irish pub': 'bottom left'}

        fig.add_trace(go.Scatter(
            x=[v1],
            y=[v2],
            mode="markers+text",
            name=n,
            text=[n],
            textposition="bottom center" if n not in location_dict else location_dict[n],
            showlegend=False,
            error_y=dict(
                type='data',
                array=[err2],
                visible=True),
            error_x=dict(
                type='data',
                array=[err1],
                visible=True)

        ))

    # add neutralization point
    opacity_list = [1, 0.8, 0.6, 0.4, 0.2, 0.1]
    for idx, op in enumerate(opacity_list):
        fig.add_trace(go.Scatter(
            x=[0],
            y=[0],
            opacity=op,
            mode="markers",  # +text
            name='neutralization',
            text=[''],
            marker=dict(size=idx * 15, color='gray'),
            textposition="bottom center",
            showlegend=False,
        ))

    fig.update_layout(autosize=True,
                      height=500,
                      width=1250,
                      margin=go.layout.Margin(
                          l=0, r=0, b=0, t=0),
                      xaxis=dict(
                          title=dict(
                              text=r"$\Large\mathrm{male} \longleftarrow \longrightarrow \mathrm{female}$",
                              font=dict(size=40))
                          , range=[x_min, x_max]
                      ),
                      yaxis=dict(
                          title=dict(
                              text=r"$\Large\mathrm{male} \longleftarrow \longrightarrow \mathrm{female}$",
                              font=dict(size=40))
                          , range=[y_min, y_max]
                      ),
                      font=dict(
                          family="Times New Roman",
                          size=20,
                      ))
    if p.save_figure:
        fig.write_image("{}nightLifes_sexualOrientation.pdf".format(saveFigure_dir), scale=1, width=1250, height=500)

    """
    5.The 1D plot for occupation and religion
    """
    print('-' * 20 + 'Generating 1D plot for occupation and religion' + '-' * 20)
    df_occupation_orig = getOccupation_df(city_list, bias_placeholder_dir, p, use_folds=True, fold_number=10)
    df_occupation_neutralized = getOccupation_df(city_list, neutralizedBias_placeholder_dir, p, use_folds=True, fold_number=10)

    """Vertical view"""
    margin = 0.03
    df_plotOrigin = create_occupationPlotDf(df_occupation_orig, type_to_show='location')
    df_plotNeutralized = create_occupationPlotDf(df_occupation_neutralized, type_to_show='location')
    df_plotOrigin_rel = create_occupationPlotDf(df_occupation_orig, type_to_show='religion')
    df_plotNeutralized_rel = create_occupationPlotDf(df_occupation_neutralized, type_to_show='religion')
    f, (ax1, ax2) = plt.subplots(1, 2, sharey=False, figsize=(6, 7))

    '''location'''
    # orig data
    y_pos = np.arange(len(df_plotOrigin))
    avg_price = df_plotOrigin['Average Price Level']
    error = df_plotOrigin['Error']

    '''neutralized data'''
    y_posNeutral = np.arange(len(df_plotNeutralized))
    avg_priceNeutral = df_plotNeutralized['Average Price Level']
    errorNeutral = df_plotNeutralized['Error']

    ax1.set_xlim(min(list(avg_price) + list(avg_priceNeutral)) - margin, max(list(avg_price) + list(avg_priceNeutral)) + margin)
    # orig data
    ax1.barh(y_pos, avg_price, xerr=error, align='center', color='white')
    ax1.plot(avg_price, y_pos, '-o', zorder=2, label='original')

    ''' neutralized data'''
    ax1.barh(y_posNeutral, avg_priceNeutral, xerr=errorNeutral, align='center', color='white')
    ax1.plot(avg_priceNeutral, y_posNeutral, '-o', zorder=2, label='neutral reference')

    ax1.set_yticks(y_pos)
    ax1.set_yticklabels(list(df_plotOrigin['Example Label']), fontsize=15)
    # plt.yticks(y_pos, labels=list(df_plotOrigin['Example Label']))
    # ax1.set_xlabel("Average Price Level")
    # ax1.legend(loc='upper left')
    '''religion'''
    # orig data
    y_pos = np.arange(len(df_plotOrigin_rel))
    avg_price = df_plotOrigin_rel['Average Price Level']
    error = df_plotOrigin_rel['Error']

    '''neutralized data'''
    y_posNeutral = np.arange(len(df_plotNeutralized_rel))
    avg_priceNeutral = df_plotNeutralized_rel['Average Price Level']
    errorNeutral = df_plotNeutralized_rel['Error']

    ax2.set_xlim(min(list(avg_price) + list(avg_priceNeutral)) - margin, max(list(avg_price) + list(avg_priceNeutral)) + margin)
    # orig data
    ax2.barh(y_pos, avg_price, xerr=error, align='center', color='white')
    ax2.plot(avg_price, y_pos, '-o', zorder=2, label='original')

    '''neutralized data'''
    ax2.barh(y_posNeutral, avg_priceNeutral, xerr=errorNeutral, align='center', color='white')
    ax2.plot(avg_priceNeutral, y_posNeutral, '-o', zorder=2, label='neutral reference')

    ax2.yaxis.tick_right()
    ax2.set_yticks(y_pos)
    ax2.set_yticklabels(list(df_plotOrigin_rel['Example Label']), fontsize=15)
    ax2.legend()

    plt.subplots_adjust(wspace=0.02, hspace=0)
    f.text(0.5, 0.04, "Average Price Level", ha='center', fontsize=15)
    plt.legend(loc='upper center', bbox_to_anchor=[0.5, 0.95], ncol=2,
               bbox_transform=plt.gcf().transFigure, fontsize=13)
    if p.save_figure:
        plt.savefig(saveFigure_dir + 'avg_price_linechart_errorBar_vertical.pdf', bbox_inches='tight')

    """
    6.Wordcloud analysis
      WordCloud based on Names
    * Joint bias
    * Single bias
    """
    print('-' * 20 + 'Generating word cloud analysis' + '-' * 20)

    # read in the dataset for all cities
    df_list_joint = []
    for cityName in city_list:
        # get reading directory
        temp_bias_dir = bias_placeholder_dir.format(cityName, p.experiment)
        temp_url = temp_bias_dir + 'yelp_qa_names.csv'
        temp_df_names = pd.read_csv(temp_url, index_col=0)
        if cityName == 'Toronto':
            temp_df_names['price_lvl'] = temp_df_names['price'].str.len()
        else:
            temp_df_names['price_lvl'] = temp_df_names['price']

        temp_df_names['city'] = cityName
        df_list_joint.append(temp_df_names)

    # concatenate all dataframes
    df_names_all = pd.concat(df_list_joint, ignore_index=True)

    # indicates how many front recommended items we want to check
    rank_bar = 20
    df_cat = df_names_all[(df_names_all['rank'] <= rank_bar)]
    df_sum = df_cat.groupby(by=['label']).size().reset_index(name='counts')
    jointCount_dict = dict()
    for index, row in tqdm(df_cat[['recommended_item', 'label']].iterrows()):
        item_name = row['recommended_item']
        label = row['label']
        innerDict = jointCount_dict.get(item_name, dict())
        innerDict[label] = innerDict.get(label, 0) + 1
        jointCount_dict[item_name] = innerDict

    """Get item polarity for different source of biases"""
    point_list = []
    dict_group = {}

    # loop through each category
    for name in df_cat['recommended_item'].unique():
        # get joint count
        x_white, x_white_count = get_counts(df_sum, jointCount_dict, name, label='white')
        x_black, x_black_count = get_counts(df_sum, jointCount_dict, name, label='black')
        y_male, y_male_count = get_counts(df_sum, jointCount_dict, name, label='male')
        y_female, y_female_count = get_counts(df_sum, jointCount_dict, name, label='female')

        if p.prob_choice_2d_plot == 'ratio':
            x_val = np.log(1e-4 + x_white / (x_black + 1e-4))
            y_val = np.log(1e-4 + y_female / (y_male + 1e-4))
        elif p.prob_choice_2d_plot == 'difference':
            x_val = (x_white - x_black) / ((x_white_count + x_black_count) / (
                    (df_sum[df_sum['label'] == 'white']['counts'].iloc[0]) + (df_sum[df_sum['label'] == 'black']['counts'].iloc[0])))
            y_val = (y_female - y_male) / ((y_female_count + y_male_count) / (
                    (df_sum[df_sum['label'] == 'male']['counts'].iloc[0]) + (df_sum[df_sum['label'] == 'female']['counts'].iloc[0])))
        else:
            raise NotImplementedError('need to choose a valid probability type')

        if (x_val, y_val) in dict_group.keys():
            dict_group[(x_val, y_val)].append(name)
        else:
            dict_group[(x_val, y_val)] = [name]

        point_list.append([name, x_val, y_val])

    """6.1 Wordcloud for joint bias"""
    print('6.1 Generating word cloud for joint bias')
    if not os.path.exists(saveFigure_dir + 'wordcloud_jointBias/'):
        os.makedirs(saveFigure_dir + 'wordcloud_jointBias/')

    item_name_dict = {'while, female': list(),
                      'white, male': list(),
                      'black, female': list(),
                      'black, male': list()}
    for item in point_list:
        n, v1, v2 = item
        if v1 > 0 and v2 > 0:
            item_name_dict['while, female'].append(n)
        elif v1 > 0 and v2 < 0:
            item_name_dict['white, male'].append(n)
        elif v1 < 0 and v2 > 0:
            item_name_dict['black, female'].append(n)
        elif v1 < 0 and v2 < 0:
            item_name_dict['black, male'].append(n)

    hide_name = ['Restaurant', 'Cafe', 'Bar', 'House', 'Bistro', 'La',
                 'Kitchen', 'Grill', 'Pizza', 'Sushi', 'Cuisine', 'Food',
                 'shops', 'food', 'store']

    replacement_dict = {name: "" for name in hide_name}
    for bias, item_names in item_name_dict.items():
        print(bias)
        wordcloud = WordCloud(collocations=False, max_words=80, background_color="white").generate(
            multireplace(' . '.join(item_names), replacement_dict))

        # Display the generated image:
        plt.figure(figsize=[10, 8])
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis("off")

        if p.save_figure:
            wordcloud.to_file(saveFigure_dir + 'wordcloud_jointBias/split_cat_{}.pdf'.format(bias.replace(', ', '_')))

    """6.2 For single bias (female, male, black, white)"""
    print('6.2 Generating word cloud for single bias')
    if not os.path.exists(saveFigure_dir + 'wordcloud_singleBias/'):
        os.makedirs(saveFigure_dir + 'wordcloud_singleBias/')
    item_name_dict = {'white': list(),
                      'black': list(),
                      'female': list(),
                      'male': list()}
    for item in point_list:
        n, v1, v2 = item
        if v1 > 0:
            item_name_dict['white'].append(n)
        if v1 < 0:
            item_name_dict['black'].append(n)
        if v2 > 0:
            item_name_dict['female'].append(n)
        if v2 < 0:
            item_name_dict['male'].append(n)

    hide_name = ['Restaurant', 'Cafe', 'Bar', 'House', 'Bistro', 'La',
                 'Kitchen', 'Grill', 'Pizza', 'Sushi', 'Cuisine', 'Food',
                 'Thai']
    hide_name.extend(city_list)
    replacement_dict = {name: "" for name in hide_name}
    for bias, item_names in item_name_dict.items():
        print(bias)
        if replacement_dict:
            wordcloud = WordCloud(collocations=False, max_words=100, background_color="white").generate(
                multireplace(' . '.join(item_names), replacement_dict))
        else:
            wordcloud = WordCloud(collocations=False, max_words=100, background_color="white").generate(' . '.join(item_names))
        plt.figure(figsize=[10, 8])
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis("off")
        if p.save_figure:
            wordcloud.to_file('{}wordcloud_singleBias/split_cat_{}.pdf'.format(saveFigure_dir, bias))

    """6.3 Sexual Orientations"""
    print('6.3 Generating word cloud for sexual orientations')
    # load all cities into one dataframe
    df_sex_orien = concat_city_df(city_list, bias_placeholder_dir, p, 'yelp_qa_relationships.csv')
    df_sex_orien['status'] = np.where(df_sex_orien['label'] == df_sex_orien['secondary_label'], 'homosexual', 'heterosexual')
    df_sex_orien['distribution'] = ''
    df_sex_orien_all = df_sex_orien[df_sex_orien['rank'] <= p.rank_threshold_all]
    df_sum_sex_orien_all = df_sex_orien_all.groupby(by=['label']).size().reset_index(name='counts')

    jointCount_dict = dict()
    lst = df_sex_orien_all.categories.values.tolist()
    lst = list(set(lst))

    for index, row in tqdm(df_sex_orien_all[['categories', 'label', 'secondary_label']].iterrows()):
        cats_string = row['categories']
        text = multireplace(cats_string, replacements)
        cats_list = text.lower().split(',')
        for cat in cats_list:
            cat = cat.strip()
            label1 = row['label'] + '_first'
            label2 = row['secondary_label'] + '_second'
            innerDict = jointCount_dict.get(cat, dict())
            innerDict[label1] = innerDict.get(label1, 0) + 1
            innerDict[label2] = innerDict.get(label2, 0) + 1
            jointCount_dict[cat] = innerDict

    point_list = []
    dict_group = {}

    # loop through each category
    for name in jointCount_dict.keys():
        x_female1, x_female_count1 = get_counts_so(df_sum_sex_orien_all, jointCount_dict, name, label='female_first')
        x_male1, x_male_count1 = get_counts_so(df_sum_sex_orien_all, jointCount_dict, name, label='male_first')
        y_female2, y_female_count2 = get_counts_so(df_sum_sex_orien_all, jointCount_dict, name, label='female_second')
        y_male2, y_male_count2 = get_counts_so(df_sum_sex_orien_all, jointCount_dict, name, label='male_second')

        # choose the probability type
        if p.prob_choice_2d_plot == 'ratio':
            x_val = np.log(1e-4 + x_female1 / (x_male1 + 1e-4))
            y_val = np.log(1e-4 + y_female_count2 / (y_male2 + 1e-4))
        elif p.prob_choice_2d_plot == 'difference':
            x_val = (x_female1 - x_male1) / ((x_female_count1 + x_male_count1) / (
                    (df_sum_sex_orien_all[df_sum_sex_orien_all['label'] == 'female']['counts'].iloc[0]) + (
                     df_sum_sex_orien_all[df_sum_sex_orien_all['label'] == 'male']['counts'].iloc[0])))
            y_val = (y_female2 - y_male2) / ((y_female_count2 + y_male_count2) / (
                    (df_sum_sex_orien_all[df_sum_sex_orien_all['label'] == 'female']['counts'].iloc[0]) + (
                     df_sum_sex_orien_all[df_sum_sex_orien_all['label'] == 'male']['counts'].iloc[0])))
        else:
            raise NotImplementedError('need to choose a valid probability type')
        if (x_val, y_val) in dict_group.keys():
            dict_group[(x_val, y_val)].append(name)
        else:
            dict_group[(x_val, y_val)] = [name]

        point_list.append([name, x_val, y_val])

    '''Choose option'''
    item_name_dict = {'homosexual': list(),
                      'heterosexual': list()}
    for item in point_list:
        n, v1, v2 = item
        # female, homosexual
        if v1 > 0.1 and v2 > 0.05:
            item_name_dict['homosexual'].append(n)
        # female, heterosexual
        if v1 > 0.1 and v2 < -0.05:
            item_name_dict['heterosexual'].append(n)
        # male, homosexual
        if v1 < -0.2 and v2 < -0.05:
            item_name_dict['homosexual'].append(n)
        # male, heterosexual
        if v1 < -0.2 and v2 > 0.05:
            item_name_dict['heterosexual'].append(n)

    hide_name = ['services', 'food', 'store', 'shops', 'boat', 'sports', 'pet', 'tours', 'garden', 'art', 'classes',
                 'stores', 'spaces', 'health', 'gift', 'specialty', 'care', 'massage',
                 'schools', 'book', 'room', 'planning', 'home', 'public', 'pool', 'furniture', 'supplies',
                 'sea', 'clothing', 'new', 'parks', 'free', 'canadian', 'golf', 'py', 'video', 'event', 'shop',
                 'creole', 'cooking', 'delivery', 'fitness', ' py  ', 'py', 'therapy', 'massage therapy',
                 'convenience', 'mortgage', 'stations', 'bed', 'teams', 'shaved', 'day', 'brokers', 'hardware', 'magazines',
                 'sitting', 'amateur', 'court', 'depment', 'depment', 'gas', 'disc', 'mirrors', 'towing', 'gyms', 'cinema',
                 'tag', 'office', 'child', 'tag', 'csa', 'supernatural', 'laser', 'rentals', 'readings', 'hair', 'instructions',
                 'study', 'outlet', 'pharmacy', 'trucks', 'ice']

    hide_name.extend(city_list)
    replacement_dict = {name: "" for name in hide_name}
    for bias, item_names in item_name_dict.items():
        print(bias)
        item_name = [name for name in item_names if name not in hide_name]

        if replacement_dict:
            wordcloud = WordCloud(collocations=False, max_words=100, background_color="white").generate(
                multireplace(' . '.join(item_names), replacement_dict).replace('py', ''))
        else:
            wordcloud = WordCloud(collocations=False, max_words=100, background_color="white").generate(' . '.join(item_names))

        plt.figure(figsize=[10, 8])
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis("off")
        if p.save_figure:
            wordcloud.to_file('{}wordcloud_singleBias/split_cat_{}.pdf'.format(saveFigure_dir, bias))
